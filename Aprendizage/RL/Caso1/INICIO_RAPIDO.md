# ğŸš€ Inicio RÃ¡pido - Reinforcement Learning

## Â¿Por dÃ³nde empiezo?

### Paso 1: Abre `index.html` en tu navegador ğŸŒ
Este es el punto de entrada principal con 3 opciones:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ§  Reinforcement Learning          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ ğŸ² Agente â”‚  â”‚ ğŸ“ Q-      â”‚      â”‚
â”‚  â”‚ Aleatorio â”‚  â”‚ Learning  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ ğŸ“š SARSA  â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“– Tutorial Paso a Paso

### Demo 1: Agente Aleatorio (5 minutos)
**Objetivo:** Entender el problema

1. Abre `random-agent.html`
2. Haz clic en "Iniciar" â–¶
3. Observa:
   - El agente se mueve sin estrategia
   - Toma muchos pasos innecesarios
   - A veces se queda atascado

**ConclusiÃ³n:** Necesitamos aprendizaje!

---

### Demo 2: Q-Learning (15 minutos)
**Objetivo:** Entrenar un agente inteligente

#### ConfiguraciÃ³n BÃ¡sica (para empezar):
```
Entorno:
  Ancho: 10
  Alto: 10
  ObstÃ¡culos: 10%

Agente:
  Alpha (Î±): 0.1
  Gamma (Î³): 0.9
  Epsilon (Îµ): 0.1
  Episodios: 1000
  
â˜ Visualizar (dÃ©jalo desactivado para mÃ¡s velocidad)
```

#### Pasos:
1. Abre `q-learning.html`
2. Haz clic en "ğŸ”„ Nuevo Entorno"
3. Configura los parÃ¡metros de arriba
4. Haz clic en "ğŸ“ Entrenar"
5. Espera ~30 segundos
6. Â¡Observa el grÃ¡fico subir! ğŸ“ˆ
7. Haz clic en "ğŸ§ª Probar"
8. Â¡Ve cÃ³mo el agente llegÃ³ al objetivo eficientemente!

**Â¿QuÃ© pasÃ³?**
- El grÃ¡fico muestra que el agente mejorÃ³ con el tiempo
- Al probarlo, usa el camino mÃ¡s Ã³ptimo
- Â¡AprendiÃ³ la polÃ­tica Ã³ptima!

---

### Demo 3: SARSA vs Q-Learning (10 minutos)
**Objetivo:** Comparar algoritmos

#### Experimento:
1. Entrena Q-Learning con:
   - Entorno: 10x10, 15% obstÃ¡culos
   - ParÃ¡metros: Î±=0.1, Î³=0.9, Îµ=0.1
   - Episodios: 1000

2. Anota el resultado:
   - Pasos promedio: ____
   - Recompensa promedio: ____

3. Entrena SARSA con **exactamente los mismos parÃ¡metros**

4. Compara:
   - Â¿CuÃ¡l aprendiÃ³ mÃ¡s rÃ¡pido?
   - Â¿CuÃ¡l tiene mejor polÃ­tica final?

**Lo que deberÃ­as notar:**
- Q-Learning es generalmente mÃ¡s agresivo
- SARSA es mÃ¡s conservador
- En este entorno determinista, ambos convergen a similar polÃ­tica

---

## ğŸ® GuÃ­a RÃ¡pida de Uso

### Controles BÃ¡sicos

#### Agente Aleatorio
```
â–¶ Iniciar     â†’ Comienza la simulaciÃ³n
â¸ Pausar      â†’ Pausa la simulaciÃ³n
â­ Paso        â†’ Ejecuta un solo paso
ğŸ”„ Reiniciar  â†’ Vuelve al inicio
```

#### Q-Learning / SARSA
```
ğŸ”„ Nuevo Entorno â†’ Crea un entorno nuevo
ğŸ“ Entrenar      â†’ Inicia el entrenamiento
â¹ Detener       â†’ Detiene el entrenamiento
ğŸ§ª Probar        â†’ Prueba el agente entrenado
```

### Atajos de Teclado
```
Agente Aleatorio:
  Espacio â†’ Iniciar/Pausar
  R       â†’ Reiniciar
  N       â†’ Nuevo entorno
  S       â†’ Paso a paso

Q-Learning/SARSA:
  Ctrl+E  â†’ Crear entorno
  Ctrl+T  â†’ Entrenar
  Ctrl+S  â†’ Detener
```

---

## ğŸ¯ Experimentos Sugeridos

### Experimento 1: Efecto de Alpha (Î±)
Entrena con diferentes Î± y compara:
- Î± = 0.01 (muy bajo)
- Î± = 0.1 (normal)
- Î± = 0.5 (alto)

**Pregunta:** Â¿CuÃ¡l aprende mÃ¡s rÃ¡pido? Â¿CuÃ¡l es mÃ¡s estable?

### Experimento 2: Efecto de Epsilon (Îµ)
- Îµ = 0.01 (poca exploraciÃ³n)
- Îµ = 0.1 (normal)
- Îµ = 0.3 (mucha exploraciÃ³n)

**Pregunta:** Â¿QuÃ© pasa si hay poca exploraciÃ³n? Â¿Y mucha?

### Experimento 3: TamaÃ±o del Entorno
- 5x5 (pequeÃ±o)
- 10x10 (mediano)
- 15x15 (grande)

**Pregunta:** Â¿CÃ³mo afecta el tamaÃ±o al tiempo de aprendizaje?

### Experimento 4: ObstÃ¡culos
- 0% obstÃ¡culos
- 10% obstÃ¡culos
- 30% obstÃ¡culos

**Pregunta:** Â¿MÃ¡s obstÃ¡culos = mÃ¡s difÃ­cil de aprender?

---

## ğŸ“Š Interpretando el GrÃ¡fico

### GrÃ¡fico Ideal
```
Recompensa
    â”‚
  0 â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â”‚              â”Œâ”€â”€â”€â”€â”€â”€
-100â”¼â”€â”€â”€        â”Œâ”€â”€â”˜
    â”‚    â•²    â•±
-200â”¼â”€â”€â”€â”€â”€â•²â”€â”€â•±
    â”‚      â•²â•±
-300â”¼â”€â”€â”€â”€â”€â”€â”€
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        Episodios
```
- **Inicio:** Recompensa muy negativa (muchos pasos)
- **Medio:** Mejora gradual
- **Final:** Se estabiliza (aprendiÃ³ la polÃ­tica)

### SeÃ±ales de Problema
```
Recompensa
    â”‚
  0 â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â”‚  â•±â•²â•±â•²â•±â•²â•±â•²â•±â•²â•±â•²â•±â•²â•±â•²
-200â”¼â”€â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â”‚
-400â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        Episodios
```
- Oscilaciones constantes
- No mejora
- **SoluciÃ³n:** Reducir Î±, aumentar episodios

---

## ğŸ” Checklist de Aprendizaje

Marca cuando hayas completado:

- [ ] CorrÃ­ la demo del agente aleatorio
- [ ] EntrenÃ© mi primer agente con Q-Learning
- [ ] ProbÃ© el agente entrenado y llegÃ³ al objetivo
- [ ] ComparÃ© Q-Learning vs SARSA
- [ ] ExperimentÃ© con diferentes valores de Î±
- [ ] ExperimentÃ© con diferentes valores de Îµ
- [ ] ProbÃ© diferentes tamaÃ±os de entorno
- [ ] Entiendo cÃ³mo leer el grÃ¡fico de aprendizaje
- [ ] Vi la polÃ­tica aprendida en la consola
- [ ] Entiendo la diferencia entre exploraciÃ³n y explotaciÃ³n

---

## ğŸ†˜ Problemas Comunes

### "El agente no llega al objetivo"
âœ… **SoluciÃ³n:** 
- Aumenta los episodios a 2000-5000
- Verifica que Î± > 0
- Aumenta Îµ para mÃ¡s exploraciÃ³n

### "El entrenamiento es muy lento"
âœ… **SoluciÃ³n:**
- Desactiva "Visualizar" durante el entrenamiento
- Reduce el tamaÃ±o del entorno
- Reduce los obstÃ¡culos

### "El grÃ¡fico no mejora"
âœ… **SoluciÃ³n:**
- Verifica los parÃ¡metros (Î±, Î³, Îµ)
- Aumenta episodios
- Reduce obstÃ¡culos
- Prueba un entorno mÃ¡s pequeÃ±o primero

### "El navegador se congela"
âœ… **SoluciÃ³n:**
- Desactiva "Visualizar"
- Reduce episodios
- Usa Chrome o Firefox (mejor rendimiento)

---

## ğŸ“ Siguiente Nivel

Cuando domines lo bÃ¡sico:

1. **Lee el cÃ³digo:**
   - `core/env_2D.js` - Entender el entorno
   - `core/agentesRL.js` - Entender los algoritmos

2. **Experimenta en la consola:**
   ```javascript
   // Ver la polÃ­tica
   agent.printPolicy();
   
   // Ver estadÃ­sticas
   agent.getQTableStats();
   
   // Exportar agente
   const data = agent.exportQTable();
   console.log(data);
   ```

3. **Modifica y experimenta:**
   - Cambia las recompensas
   - AÃ±ade nuevas acciones
   - Crea nuevos entornos

---

## ğŸ“š Recursos de Aprendizaje

### En orden de prioridad:
1. **Este README** (lo estÃ¡s leyendo)
2. **README.md** (documentaciÃ³n completa)
3. **El cÃ³digo** (bien comentado)
4. **Libro:** "Reinforcement Learning: An Introduction" - Sutton & Barto
5. **Video:** David Silver's RL Course (YouTube)

---

## ğŸ’¡ Tips Finales

1. **Empieza simple:** 5x5 sin obstÃ¡culos
2. **Ve aumentando:** AÃ±ade complejidad gradualmente
3. **Compara:** Corre el mismo experimento varias veces
4. **Anota:** Guarda los mejores parÃ¡metros que encuentres
5. **Experimenta:** No tengas miedo de probar cosas nuevas

---

**Â¿Listo? Â¡Abre `index.html` y comienza tu viaje en Reinforcement Learning!** ğŸš€

